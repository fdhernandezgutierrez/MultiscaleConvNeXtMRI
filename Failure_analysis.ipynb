{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3c09a85-732b-4824-bbdf-65dc0e365d07",
      "metadata": {
        "id": "c3c09a85-732b-4824-bbdf-65dc0e365d07",
        "outputId": "c85cd8c9-743b-425b-fe38-96eb47966d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output: torch.Size([2, 1, 512, 512])\n"
          ]
        }
      ],
      "source": [
        "%run src/ConvNext_models.ipynb\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f50f463b-6b16-46f9-aa17-4ddfac18ae69",
      "metadata": {
        "id": "f50f463b-6b16-46f9-aa17-4ddfac18ae69"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BRATSDataset_2(Dataset):\n",
        "    def __init__(self, base_path, img_transform=None, mask_transform=None, year=2023):\n",
        "        self.base_path = base_path\n",
        "\n",
        "        self.folders = [f for f in os.listdir(base_path)\n",
        "                        if os.path.isdir(os.path.join(base_path, f))]\n",
        "        self.transform = img_transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.year = year\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.folders)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        folder_name = self.folders[idx]\n",
        "        folder_path = os.path.join(self.base_path, folder_name)\n",
        "        files = os.listdir(folder_path)\n",
        "\n",
        "        t2f_file, seg_file = None, None\n",
        "\n",
        "        for nifty_file in files:\n",
        "            file_path = os.path.join(folder_path, nifty_file)\n",
        "\n",
        "            try:\n",
        "\n",
        "                if nifty_file.endswith('.nii') and 't2f' in nifty_file:\n",
        "                    t2f_file = nib.load(file_path).get_fdata()\n",
        "                elif nifty_file.endswith('.nii') and 'seg' in nifty_file:\n",
        "                    seg_file = nib.load(file_path).get_fdata()\n",
        "                elif nifty_file.endswith('.nii.gz') and 't2' in nifty_file:\n",
        "                    t2f_file = nib.load(file_path).get_fdata()\n",
        "                elif nifty_file.endswith('.nii.gz') and 'seg' in nifty_file:\n",
        "                    seg_file = nib.load(file_path).get_fdata()\n",
        "            except Exception as e:\n",
        "                print(f\"Error al cargar {file_path}: {e}\")\n",
        "\n",
        "                return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "        if t2f_file is None or seg_file is None:\n",
        "            print(f\"Advertencia: Archivo t2f o segmentación faltante en {folder_path}.\")\n",
        "\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "\n",
        "        max_content_slice = np.argmax(np.sum(seg_file, axis=(0, 1)))\n",
        "\n",
        "\n",
        "        t2f_image = t2f_file[:, :, max_content_slice]\n",
        "        seg_image = (seg_file[:, :, max_content_slice] > 0).astype(np.uint8)\n",
        "\n",
        "\n",
        "        t2f_image = torch.tensor(t2f_image, dtype=torch.float32).unsqueeze(0)\n",
        "        seg_image = torch.tensor(seg_image, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            t2f_image = self.transform(t2f_image)\n",
        "\n",
        "        if self.mask_transform:\n",
        "            seg_image = self.mask_transform(seg_image)\n",
        "\n",
        "\n",
        "        case_id = folder_name\n",
        "\n",
        "\n",
        "        return t2f_image, seg_image, case_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e98a055e-2054-4af6-a03e-bbaab53de36f",
      "metadata": {
        "id": "e98a055e-2054-4af6-a03e-bbaab53de36f",
        "outputId": "cd52b173-c43c-4525-f588-e3d701fd8d59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146\n"
          ]
        }
      ],
      "source": [
        "base_path =\"../datasets/BRATS2021/\"\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512))\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "dataset = BRATSDataset_2(base_path, img_transform=transform, mask_transform = mask_transform)\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size   = int(0.15 * len(dataset))\n",
        "test_size  = len(dataset) - train_size - val_size\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "\n",
        "BATCH_SIZE = 6\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size   = BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size  = BATCH_SIZE, shuffle=False)\n",
        "print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4199cef1-3ffe-4c8c-a63f-c38094f8d5f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "4199cef1-3ffe-4c8c-a63f-c38094f8d5f8",
        "outputId": "a12c191c-a826-4a58-ec37-b63e4ce5164a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated f-string literal (detected at line 265) (ipython-input-2604204789.py, line 265)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2604204789.py\"\u001b[0;36m, line \u001b[0;32m265\u001b[0m\n\u001b[0;31m    print(f\"[INFO] Quanti\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated f-string literal (detected at line 265)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.cluster import DBSCAN\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def analyze_slice_with_dbscan(gt_2d,\n",
        "                              pred_2d,\n",
        "                              eps=3,\n",
        "                              min_samples=20):\n",
        "    gt = gt_2d.astype(bool)\n",
        "    pred = pred_2d.astype(bool)\n",
        "\n",
        "\n",
        "    fn_mask = np.logical_and(gt, np.logical_not(pred))\n",
        "\n",
        "    fp_mask = np.logical_and(np.logical_not(gt), pred)\n",
        "\n",
        "    fn_coords = np.argwhere(fn_mask)\n",
        "    fp_coords = np.argwhere(fp_mask)\n",
        "\n",
        "    results = {\n",
        "        \"fn_clusters\": [],\n",
        "        \"fp_clusters\": [],\n",
        "        \"n_fn_pixels\": int(fn_coords.shape[0]),\n",
        "        \"n_fp_pixels\": int(fp_coords.shape[0]),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if fn_coords.shape[0] > 0:\n",
        "        db_fn = DBSCAN(eps=eps, min_samples=min_samples).fit(fn_coords)\n",
        "        labels_fn = db_fn.labels_\n",
        "\n",
        "        for lab in set(labels_fn):\n",
        "            if lab == -1:\n",
        "                continue\n",
        "            mask_lab = (labels_fn == lab)\n",
        "            coords_lab = fn_coords[mask_lab]\n",
        "\n",
        "            size = int(coords_lab.shape[0])\n",
        "            y_mean, x_mean = coords_lab.mean(axis=0)\n",
        "\n",
        "            results[\"fn_clusters\"].append({\n",
        "                \"cluster_id\": int(lab),\n",
        "                \"size\": size,\n",
        "                \"centroid_rowcol\": (float(y_mean), float(x_mean)),\n",
        "            })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if fp_coords.shape[0] > 0:\n",
        "        db_fp = DBSCAN(eps=eps, min_samples=min_samples).fit(fp_coords)\n",
        "        labels_fp = db_fp.labels_\n",
        "\n",
        "        for lab in set(labels_fp):\n",
        "            if lab == -1:\n",
        "                continue\n",
        "            mask_lab = (labels_fp == lab)\n",
        "            coords_lab = fp_coords[mask_lab]\n",
        "\n",
        "            size = int(coords_lab.shape[0])\n",
        "            y_mean, x_mean = coords_lab.mean(axis=0)\n",
        "\n",
        "            results[\"fp_clusters\"].append({\n",
        "                \"cluster_id\": int(lab),\n",
        "                \"size\": size,\n",
        "                \"centroid_rowcol\": (float(y_mean), float(x_mean)),\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dice_score_torch(pred, gt, eps=1e-7):\n",
        "    if pred.dim() == 4:\n",
        "        pred = pred[:, 0]\n",
        "        gt   = gt[:, 0]\n",
        "\n",
        "    pred = pred.float()\n",
        "    gt   = gt.float()\n",
        "\n",
        "    inter = (pred * gt).sum()\n",
        "    denom = pred.sum() + gt.sum()\n",
        "    return float((2 * inter + eps) / (denom + eps))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run_failure_analysis(model,\n",
        "                         test_loader,\n",
        "                         device=None,\n",
        "                         eps=3,\n",
        "                         min_samples=20,\n",
        "                         save_json_path=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_slices_results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, gts, names in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            gts  = gts.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            logits = model(imgs)\n",
        "\n",
        "\n",
        "            if logits.shape[1] == 1:\n",
        "                probs = torch.sigmoid(logits)\n",
        "            else:\n",
        "\n",
        "                probs = torch.softmax(logits, dim=1)[:, 1:2, ...]\n",
        "\n",
        "\n",
        "            preds = (probs > 0.5).long()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            batch_size = imgs.size(0)\n",
        "            for b in range(batch_size):\n",
        "                gt_b   = gts[b, 0].cpu().numpy()\n",
        "                pred_b = preds[b, 0].cpu().numpy()\n",
        "\n",
        "\n",
        "                dbscan_res = analyze_slice_with_dbscan(\n",
        "                    gt_2d=gt_b,\n",
        "                    pred_2d=pred_b,\n",
        "                    eps=eps,\n",
        "                    min_samples=min_samples\n",
        "                )\n",
        "\n",
        "\n",
        "                dice_b = dice_score_torch(preds[b:b+1], gts[b:b+1])\n",
        "\n",
        "\n",
        "                tumor_pixels = int(gt_b.sum())\n",
        "\n",
        "                slice_result = {\n",
        "                    \"name\": str(names[b]),\n",
        "                    \"dice\": dice_b,\n",
        "                    \"n_fn_pixels\": dbscan_res[\"n_fn_pixels\"],\n",
        "                    \"n_fp_pixels\": dbscan_res[\"n_fp_pixels\"],\n",
        "                    \"fn_clusters\": dbscan_res[\"fn_clusters\"],\n",
        "                    \"fp_clusters\": dbscan_res[\"fp_clusters\"],\n",
        "                    \"tumor_pixels_gt\": tumor_pixels,\n",
        "                }\n",
        "                all_slices_results.append(slice_result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if save_json_path is not None:\n",
        "        os.makedirs(os.path.dirname(save_json_path), exist_ok=True)\n",
        "        with open(save_json_path, \"w\") as f:\n",
        "            json.dump(all_slices_results, f, indent=2)\n",
        "        print(f\"[INFO] Resultados guardados en: {save_json_path}\")\n",
        "\n",
        "    return all_slices_results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def count_big_fn_clusters(r, min_size=100):\n",
        "    return sum(1 for c in r[\"fn_clusters\"] if c[\"size\"] >= min_size)\n",
        "\n",
        "\n",
        "def stratify_by_tumor_size(all_results, big_fn_min_size=100):\n",
        "    sizes = [r[\"tumor_pixels_gt\"] for r in all_results if r[\"tumor_pixels_gt\"] > 0]\n",
        "\n",
        "    if len(sizes) == 0:\n",
        "        print(\"[WARN] No hay slices con tumor (tumor_pixels_gt > 0).\")\n",
        "        return [], None, None\n",
        "\n",
        "    sizes_arr = np.array(sizes)\n",
        "    q1, q2 = np.percentile(sizes_arr, [33, 66])\n",
        "    print(f\"[INFO] Quanti\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6138781c-19d5-44e0-bdd3-afcf137cb5af",
      "metadata": {
        "id": "6138781c-19d5-44e0-bdd3-afcf137cb5af"
      },
      "source": [
        "# Failure analisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b18e9e64-fe1c-4ad3-b3df-ad6b0f94f90e",
      "metadata": {
        "scrolled": true,
        "id": "b18e9e64-fe1c-4ad3-b3df-ad6b0f94f90e",
        "outputId": "4b778c9f-527d-45dd-b17e-d56b52161b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using device: cuda\n",
            "[INFO] Loaded checkpoint as plain state_dict.\n",
            "[INFO] Resultados guardados en: ./failure_analysis/dbscan_results.json\n",
            "\n",
            "=== Slices con clústeres FN grandes (>100 píxeles) ===\n",
            "Slice: BraTS2021_01570, Dice=0.9571, Big FN clusters=3\n",
            "Slice: BraTS2021_00578, Dice=0.9499, Big FN clusters=4\n",
            "Slice: BraTS2021_00380, Dice=0.8843, Big FN clusters=2\n",
            "Slice: BraTS2021_00241, Dice=0.9592, Big FN clusters=1\n",
            "Slice: BraTS2021_00155, Dice=0.8206, Big FN clusters=4\n",
            "Slice: BraTS2021_00605, Dice=0.9595, Big FN clusters=5\n",
            "Slice: BraTS2021_00759, Dice=0.9311, Big FN clusters=3\n",
            "Slice: BraTS2021_01164, Dice=0.9312, Big FN clusters=5\n",
            "Slice: BraTS2021_00286, Dice=0.5821, Big FN clusters=3\n",
            "Slice: BraTS2021_01415, Dice=0.7721, Big FN clusters=2\n",
            "Slice: BraTS2021_00397, Dice=0.8802, Big FN clusters=3\n",
            "Slice: BraTS2021_00113, Dice=0.8636, Big FN clusters=3\n",
            "Slice: BraTS2021_00012, Dice=0.9446, Big FN clusters=4\n",
            "Slice: BraTS2021_01172, Dice=0.9446, Big FN clusters=3\n",
            "Slice: BraTS2021_01625, Dice=0.9090, Big FN clusters=2\n",
            "Slice: BraTS2021_01124, Dice=0.9252, Big FN clusters=2\n",
            "Slice: BraTS2021_00325, Dice=0.9330, Big FN clusters=6\n",
            "Slice: BraTS2021_00162, Dice=0.9049, Big FN clusters=1\n",
            "Slice: BraTS2021_01464, Dice=0.8942, Big FN clusters=1\n",
            "Slice: BraTS2021_00432, Dice=0.9205, Big FN clusters=4\n",
            "Slice: BraTS2021_01197, Dice=0.9066, Big FN clusters=3\n",
            "Slice: BraTS2021_00413, Dice=0.9502, Big FN clusters=1\n",
            "Slice: BraTS2021_00400, Dice=0.9457, Big FN clusters=4\n",
            "Slice: BraTS2021_01100, Dice=0.9483, Big FN clusters=3\n",
            "Slice: BraTS2021_01619, Dice=0.9551, Big FN clusters=3\n",
            "Slice: BraTS2021_01517, Dice=0.8969, Big FN clusters=6\n",
            "Slice: BraTS2021_00510, Dice=0.9091, Big FN clusters=3\n",
            "Slice: BraTS2021_01231, Dice=0.8372, Big FN clusters=5\n",
            "Slice: BraTS2021_01198, Dice=0.7915, Big FN clusters=4\n",
            "Slice: BraTS2021_00800, Dice=0.8626, Big FN clusters=1\n",
            "Slice: BraTS2021_01454, Dice=0.8993, Big FN clusters=3\n",
            "Slice: BraTS2021_01250, Dice=0.9182, Big FN clusters=1\n",
            "Slice: BraTS2021_00095, Dice=0.9518, Big FN clusters=1\n",
            "Slice: BraTS2021_00304, Dice=0.9377, Big FN clusters=4\n",
            "Slice: BraTS2021_00219, Dice=0.7982, Big FN clusters=3\n",
            "Slice: BraTS2021_01337, Dice=0.9109, Big FN clusters=2\n",
            "Slice: BraTS2021_01443, Dice=0.8993, Big FN clusters=1\n",
            "Slice: BraTS2021_00140, Dice=0.8646, Big FN clusters=2\n",
            "Slice: BraTS2021_01076, Dice=0.9654, Big FN clusters=3\n",
            "Slice: BraTS2021_01123, Dice=0.9312, Big FN clusters=2\n",
            "Slice: BraTS2021_00751, Dice=0.9184, Big FN clusters=3\n",
            "Slice: BraTS2021_01440, Dice=0.9344, Big FN clusters=1\n",
            "Slice: BraTS2021_01330, Dice=0.8753, Big FN clusters=3\n",
            "Slice: BraTS2021_01079, Dice=0.9410, Big FN clusters=5\n",
            "Slice: BraTS2021_01393, Dice=0.9574, Big FN clusters=1\n",
            "Slice: BraTS2021_01646, Dice=0.7951, Big FN clusters=5\n",
            "Slice: BraTS2021_00580, Dice=0.9281, Big FN clusters=5\n",
            "Slice: BraTS2021_00238, Dice=0.8964, Big FN clusters=3\n",
            "Slice: BraTS2021_00109, Dice=0.9326, Big FN clusters=5\n",
            "Slice: BraTS2021_01056, Dice=0.8412, Big FN clusters=9\n",
            "Slice: BraTS2021_01388, Dice=0.9666, Big FN clusters=1\n",
            "Slice: BraTS2021_00373, Dice=0.9378, Big FN clusters=1\n",
            "Slice: BraTS2021_00410, Dice=0.7537, Big FN clusters=2\n",
            "Slice: BraTS2021_00000, Dice=0.9049, Big FN clusters=5\n",
            "Slice: BraTS2021_00425, Dice=0.9030, Big FN clusters=1\n",
            "Slice: BraTS2021_00723, Dice=0.9323, Big FN clusters=2\n",
            "Slice: BraTS2021_01194, Dice=0.8644, Big FN clusters=4\n",
            "Slice: BraTS2021_01496, Dice=0.9347, Big FN clusters=4\n",
            "Slice: BraTS2021_01204, Dice=0.6277, Big FN clusters=2\n",
            "Slice: BraTS2021_01363, Dice=0.9262, Big FN clusters=1\n",
            "Slice: BraTS2021_00052, Dice=0.8659, Big FN clusters=2\n",
            "Slice: BraTS2021_00494, Dice=0.7800, Big FN clusters=3\n",
            "Slice: BraTS2021_01160, Dice=0.8762, Big FN clusters=4\n",
            "Slice: BraTS2021_01358, Dice=0.9467, Big FN clusters=3\n",
            "Slice: BraTS2021_00090, Dice=0.9405, Big FN clusters=3\n",
            "Slice: BraTS2021_00143, Dice=0.8804, Big FN clusters=6\n",
            "Slice: BraTS2021_00339, Dice=0.9392, Big FN clusters=4\n",
            "Slice: BraTS2021_00033, Dice=0.9601, Big FN clusters=4\n",
            "Slice: BraTS2021_01260, Dice=0.9144, Big FN clusters=2\n",
            "Slice: BraTS2021_01030, Dice=0.8452, Big FN clusters=2\n",
            "Slice: BraTS2021_00058, Dice=0.9288, Big FN clusters=3\n",
            "Slice: BraTS2021_01264, Dice=0.8684, Big FN clusters=4\n",
            "Slice: BraTS2021_01647, Dice=0.8352, Big FN clusters=3\n",
            "Slice: BraTS2021_00641, Dice=0.9257, Big FN clusters=4\n",
            "Slice: BraTS2021_01029, Dice=0.9588, Big FN clusters=3\n",
            "Slice: BraTS2021_01451, Dice=0.7369, Big FN clusters=1\n",
            "Slice: BraTS2021_01528, Dice=0.7308, Big FN clusters=2\n",
            "Slice: BraTS2021_01165, Dice=0.8716, Big FN clusters=1\n",
            "Slice: BraTS2021_00054, Dice=0.8971, Big FN clusters=5\n",
            "Slice: BraTS2021_01595, Dice=0.9320, Big FN clusters=2\n",
            "Slice: BraTS2021_01149, Dice=0.8036, Big FN clusters=1\n",
            "Slice: BraTS2021_01406, Dice=0.8353, Big FN clusters=6\n",
            "Slice: BraTS2021_01418, Dice=0.9616, Big FN clusters=1\n",
            "Slice: BraTS2021_00138, Dice=0.9250, Big FN clusters=8\n",
            "Slice: BraTS2021_01167, Dice=0.6948, Big FN clusters=3\n",
            "Slice: BraTS2021_01526, Dice=0.9522, Big FN clusters=1\n",
            "Slice: BraTS2021_01085, Dice=0.9583, Big FN clusters=1\n",
            "Slice: BraTS2021_01036, Dice=0.8985, Big FN clusters=3\n",
            "Slice: BraTS2021_01062, Dice=0.9626, Big FN clusters=2\n",
            "Slice: BraTS2021_01235, Dice=0.9341, Big FN clusters=3\n",
            "Slice: BraTS2021_01052, Dice=0.9243, Big FN clusters=4\n",
            "Slice: BraTS2021_00188, Dice=0.9032, Big FN clusters=4\n",
            "Slice: BraTS2021_01166, Dice=0.9052, Big FN clusters=3\n",
            "Slice: BraTS2021_00708, Dice=0.6869, Big FN clusters=2\n",
            "Slice: BraTS2021_00089, Dice=0.9236, Big FN clusters=4\n",
            "Slice: BraTS2021_00834, Dice=0.8282, Big FN clusters=4\n",
            "Slice: BraTS2021_01410, Dice=0.8887, Big FN clusters=2\n",
            "Slice: BraTS2021_00620, Dice=0.9440, Big FN clusters=3\n",
            "Slice: BraTS2021_01192, Dice=0.8864, Big FN clusters=5\n",
            "Slice: BraTS2021_00347, Dice=0.9378, Big FN clusters=1\n",
            "Slice: BraTS2021_01326, Dice=0.9333, Big FN clusters=4\n",
            "Slice: BraTS2021_00831, Dice=0.9001, Big FN clusters=2\n",
            "Slice: BraTS2021_00273, Dice=0.9601, Big FN clusters=1\n",
            "Slice: BraTS2021_01227, Dice=0.9398, Big FN clusters=2\n",
            "Slice: BraTS2021_01073, Dice=0.9647, Big FN clusters=1\n",
            "Slice: BraTS2021_00184, Dice=0.8634, Big FN clusters=3\n",
            "Slice: BraTS2021_00193, Dice=0.9313, Big FN clusters=1\n",
            "Slice: BraTS2021_00151, Dice=0.9294, Big FN clusters=8\n",
            "Slice: BraTS2021_00002, Dice=0.9297, Big FN clusters=6\n",
            "Slice: BraTS2021_01428, Dice=0.9530, Big FN clusters=4\n",
            "Slice: BraTS2021_00639, Dice=0.9633, Big FN clusters=1\n",
            "Slice: BraTS2021_01357, Dice=0.9324, Big FN clusters=1\n",
            "Slice: BraTS2021_00451, Dice=0.9381, Big FN clusters=4\n",
            "Slice: BraTS2021_00048, Dice=0.9289, Big FN clusters=3\n",
            "Slice: BraTS2021_01183, Dice=0.9264, Big FN clusters=3\n",
            "Slice: BraTS2021_00612, Dice=0.9650, Big FN clusters=4\n",
            "Slice: BraTS2021_00523, Dice=0.9422, Big FN clusters=3\n",
            "Slice: BraTS2021_00496, Dice=0.8222, Big FN clusters=3\n",
            "Slice: BraTS2021_00693, Dice=0.9272, Big FN clusters=6\n",
            "Slice: BraTS2021_01020, Dice=0.9488, Big FN clusters=1\n",
            "Slice: BraTS2021_00542, Dice=0.9205, Big FN clusters=4\n",
            "Slice: BraTS2021_01263, Dice=0.9469, Big FN clusters=1\n",
            "Slice: BraTS2021_00068, Dice=0.9208, Big FN clusters=3\n",
            "Slice: BraTS2021_00214, Dice=0.9344, Big FN clusters=2\n",
            "Slice: BraTS2021_01346, Dice=0.9622, Big FN clusters=1\n",
            "Slice: BraTS2021_00767, Dice=0.9507, Big FN clusters=3\n",
            "Slice: BraTS2021_00183, Dice=0.9524, Big FN clusters=1\n",
            "Slice: BraTS2021_01138, Dice=0.6671, Big FN clusters=9\n",
            "Slice: BraTS2021_01071, Dice=0.9067, Big FN clusters=3\n",
            "Slice: BraTS2021_00636, Dice=0.8418, Big FN clusters=1\n",
            "Slice: BraTS2021_01181, Dice=0.9386, Big FN clusters=2\n",
            "Slice: BraTS2021_00459, Dice=0.9400, Big FN clusters=2\n",
            "Slice: BraTS2021_00646, Dice=0.9219, Big FN clusters=2\n",
            "Slice: BraTS2021_01634, Dice=0.9425, Big FN clusters=4\n",
            "Slice: BraTS2021_00097, Dice=0.9361, Big FN clusters=1\n",
            "Slice: BraTS2021_01016, Dice=0.8531, Big FN clusters=5\n",
            "Slice: BraTS2021_01069, Dice=0.9609, Big FN clusters=1\n",
            "Slice: BraTS2021_01409, Dice=0.8792, Big FN clusters=3\n",
            "Slice: BraTS2021_01558, Dice=0.8488, Big FN clusters=3\n",
            "Slice: BraTS2021_01547, Dice=0.8454, Big FN clusters=3\n",
            "Slice: BraTS2021_01153, Dice=0.8916, Big FN clusters=2\n",
            "Slice: BraTS2021_00263, Dice=0.9092, Big FN clusters=2\n",
            "Slice: BraTS2021_01565, Dice=0.9274, Big FN clusters=4\n",
            "Slice: BraTS2021_01575, Dice=0.9628, Big FN clusters=1\n",
            "Slice: BraTS2021_01465, Dice=0.9622, Big FN clusters=2\n",
            "Slice: BraTS2021_00320, Dice=0.9202, Big FN clusters=2\n",
            "Slice: BraTS2021_01543, Dice=0.9266, Big FN clusters=3\n",
            "Slice: BraTS2021_00532, Dice=0.9608, Big FN clusters=2\n",
            "Slice: BraTS2021_01002, Dice=0.9155, Big FN clusters=5\n",
            "Slice: BraTS2021_00511, Dice=0.8954, Big FN clusters=6\n",
            "Slice: BraTS2021_01437, Dice=0.9282, Big FN clusters=4\n",
            "Slice: BraTS2021_01411, Dice=0.8886, Big FN clusters=3\n",
            "Slice: BraTS2021_01057, Dice=0.9302, Big FN clusters=1\n",
            "Slice: BraTS2021_00803, Dice=0.9518, Big FN clusters=3\n",
            "Slice: BraTS2021_01215, Dice=0.9297, Big FN clusters=2\n",
            "Slice: BraTS2021_01127, Dice=0.8281, Big FN clusters=2\n",
            "Slice: BraTS2021_00108, Dice=0.8881, Big FN clusters=3\n",
            "Slice: BraTS2021_00485, Dice=0.7818, Big FN clusters=3\n",
            "Slice: BraTS2021_01295, Dice=0.9177, Big FN clusters=3\n",
            "Slice: BraTS2021_00309, Dice=0.9302, Big FN clusters=1\n",
            "Slice: BraTS2021_01605, Dice=0.9521, Big FN clusters=5\n",
            "Slice: BraTS2021_01456, Dice=0.9438, Big FN clusters=3\n",
            "Slice: BraTS2021_01637, Dice=0.8166, Big FN clusters=4\n",
            "Slice: BraTS2021_01014, Dice=0.8401, Big FN clusters=3\n",
            "Slice: BraTS2021_01298, Dice=0.9274, Big FN clusters=4\n",
            "Slice: BraTS2021_01248, Dice=0.8894, Big FN clusters=5\n",
            "Slice: BraTS2021_01490, Dice=0.9685, Big FN clusters=2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def analyze_slice_with_dbscan(gt_2d,\n",
        "                              pred_2d,\n",
        "                              eps=3,\n",
        "                              min_samples=20):\n",
        "    gt = gt_2d.astype(bool)\n",
        "    pred = pred_2d.astype(bool)\n",
        "\n",
        "\n",
        "    fn_mask = np.logical_and(gt, np.logical_not(pred))\n",
        "\n",
        "    fp_mask = np.logical_and(np.logical_not(gt), pred)\n",
        "\n",
        "    fn_coords = np.argwhere(fn_mask)\n",
        "    fp_coords = np.argwhere(fp_mask)\n",
        "\n",
        "    results = {\n",
        "        \"fn_clusters\": [],\n",
        "        \"fp_clusters\": [],\n",
        "        \"n_fn_pixels\": int(fn_coords.shape[0]),\n",
        "        \"n_fp_pixels\": int(fp_coords.shape[0]),\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if fn_coords.shape[0] > 0:\n",
        "        db_fn = DBSCAN(eps=eps, min_samples=min_samples).fit(fn_coords)\n",
        "        labels_fn = db_fn.labels_\n",
        "\n",
        "        for lab in set(labels_fn):\n",
        "            if lab == -1:\n",
        "                continue\n",
        "            mask_lab = (labels_fn == lab)\n",
        "            coords_lab = fn_coords[mask_lab]\n",
        "\n",
        "            size = int(coords_lab.shape[0])\n",
        "            y_mean, x_mean = coords_lab.mean(axis=0)\n",
        "\n",
        "            results[\"fn_clusters\"].append({\n",
        "                \"cluster_id\": int(lab),\n",
        "                \"size\": size,\n",
        "                \"centroid_rowcol\": (float(y_mean), float(x_mean)),\n",
        "            })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if fp_coords.shape[0] > 0:\n",
        "        db_fp = DBSCAN(eps=eps, min_samples=min_samples).fit(fp_coords)\n",
        "        labels_fp = db_fp.labels_\n",
        "\n",
        "        for lab in set(labels_fp):\n",
        "            if lab == -1:\n",
        "                continue\n",
        "            mask_lab = (labels_fp == lab)\n",
        "            coords_lab = fp_coords[mask_lab]\n",
        "\n",
        "            size = int(coords_lab.shape[0])\n",
        "            y_mean, x_mean = coords_lab.mean(axis=0)\n",
        "\n",
        "            results[\"fp_clusters\"].append({\n",
        "                \"cluster_id\": int(lab),\n",
        "                \"size\": size,\n",
        "                \"centroid_rowcol\": (float(y_mean), float(x_mean)),\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dice_score_torch(pred, gt, eps=1e-7):\n",
        "    if pred.dim() == 4:\n",
        "        pred = pred[:, 0]\n",
        "        gt   = gt[:, 0]\n",
        "\n",
        "    pred = pred.float()\n",
        "    gt   = gt.float()\n",
        "\n",
        "    inter = (pred * gt).sum()\n",
        "    denom = pred.sum() + gt.sum()\n",
        "    return float((2 * inter + eps) / (denom + eps))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def run_failure_analysis(model,\n",
        "                         test_loader,\n",
        "                         device=None,\n",
        "                         eps=3,\n",
        "                         min_samples=20,\n",
        "                         save_json_path=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_slices_results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, gts, names in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            gts  = gts.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            logits = model(imgs)\n",
        "\n",
        "\n",
        "            if logits.shape[1] == 1:\n",
        "                probs = torch.sigmoid(logits)\n",
        "            else:\n",
        "\n",
        "                probs = torch.softmax(logits, dim=1)[:, 1:2, ...]\n",
        "\n",
        "\n",
        "            preds = (probs > 0.5).long()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            batch_size = imgs.size(0)\n",
        "            for b in range(batch_size):\n",
        "                gt_b   = gts[b, 0].cpu().numpy()\n",
        "                pred_b = preds[b, 0].cpu().numpy()\n",
        "\n",
        "\n",
        "                dbscan_res = analyze_slice_with_dbscan(\n",
        "                    gt_2d=gt_b,\n",
        "                    pred_2d=pred_b,\n",
        "                    eps=eps,\n",
        "                    min_samples=min_samples\n",
        "                )\n",
        "\n",
        "\n",
        "                dice_b = dice_score_torch(preds[b:b+1], gts[b:b+1])\n",
        "\n",
        "                slice_result = {\n",
        "                    \"name\": str(names[b]),\n",
        "                    \"dice\": dice_b,\n",
        "                    \"n_fn_pixels\": dbscan_res[\"n_fn_pixels\"],\n",
        "                    \"n_fp_pixels\": dbscan_res[\"n_fp_pixels\"],\n",
        "                    \"fn_clusters\": dbscan_res[\"fn_clusters\"],\n",
        "                    \"fp_clusters\": dbscan_res[\"fp_clusters\"],\n",
        "                }\n",
        "                all_slices_results.append(slice_result)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if save_json_path is not None:\n",
        "        os.makedirs(os.path.dirname(save_json_path), exist_ok=True)\n",
        "        with open(save_json_path, \"w\") as f:\n",
        "            json.dump(all_slices_results, f, indent=2)\n",
        "        print(f\"[INFO] Resultados guardados en: {save_json_path}\")\n",
        "\n",
        "    return all_slices_results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"[INFO] Using device:\", device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model = ConvNeXtSegmentationMF(\n",
        "            num_classes   = 1,\n",
        "            backbone_type = 'base')\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ckpt_path = \"pretrained_model/ConvNeXtSegmentationMF_fold1_2021.pth\"\n",
        "\n",
        "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "    if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        print(\"[INFO] Loaded checkpoint['model_state_dict'].\")\n",
        "    else:\n",
        "        model.load_state_dict(checkpoint)\n",
        "        print(\"[INFO] Loaded checkpoint as plain state_dict.\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    all_results = run_failure_analysis(\n",
        "         model=model,\n",
        "         test_loader=test_loader,\n",
        "         device=device,\n",
        "         eps=3,\n",
        "         min_samples=20,\n",
        "         save_json_path=\"./failure_analysis/dbscan_results.json\"\n",
        "     )\n",
        "\n",
        "\n",
        "    print(\"\\n=== Slices con clústeres FN grandes (>100 píxeles) ===\")\n",
        "    for r in all_results:\n",
        "         big_fn = [c for c in r[\"fn_clusters\"] if c[\"size\"] > 100]\n",
        "         if len(big_fn) > 0:\n",
        "             print(f\"Slice: {r['name']}, Dice={r['dice']:.4f}, \"\n",
        "                   f\"Big FN clusters={len(big_fn)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7989f50a-dc72-4c80-869f-4a04e5a3714b",
      "metadata": {
        "id": "7989f50a-dc72-4c80-869f-4a04e5a3714b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def dice_coefficient(pred, target, eps=1e-6):\n",
        "    if pred.dim() == 3:\n",
        "        pred = pred.squeeze(0)\n",
        "    if target.dim() == 3:\n",
        "        target = target.squeeze(0)\n",
        "\n",
        "    pred = pred.float()\n",
        "    target = target.float()\n",
        "\n",
        "    intersection = (pred * target).sum()\n",
        "    union = pred.sum() + target.sum()\n",
        "    dice = (2.0 * intersection + eps) / (union + eps)\n",
        "    return dice.item()\n",
        "\n",
        "\n",
        "def run_failure_analysis(model, test_loader, device, dice_threshold=0.70):\n",
        "    model.eval()\n",
        "    results = []\n",
        "\n",
        "    debug_limit = 10\n",
        "    debug_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, gts, case_ids in test_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            gts  = gts.to(device)\n",
        "\n",
        "            logits = model(imgs)\n",
        "\n",
        "            preds  = (logits > 0.4).float()\n",
        "\n",
        "            B = imgs.size(0)\n",
        "            for i in range(B):\n",
        "                cid = case_ids[i]\n",
        "                pred_slice = preds[i, 0].cpu()\n",
        "                gt_slice   = gts[i, 0].cpu()\n",
        "\n",
        "                dice_wt = dice_coefficient(pred_slice, gt_slice)\n",
        "                volume_voxels = gt_slice.sum().item()\n",
        "                pred_voxels   = pred_slice.sum().item()\n",
        "                intersec      = (pred_slice * gt_slice).sum().item()\n",
        "\n",
        "\n",
        "                if debug_count < debug_limit:\n",
        "                    print(\n",
        "                        f\"{cid} | Dice: {dice_wt:.4f} | \"\n",
        "                        f\"GT voxels: {volume_voxels:.0f} | \"\n",
        "                        f\"Pred voxels: {pred_voxels:.0f} | \"\n",
        "                        f\"Intersec: {intersec:.0f}\"\n",
        "                    )\n",
        "                    debug_count += 1\n",
        "\n",
        "                results.append({\n",
        "                    \"case_id\": cid,\n",
        "                    \"dice_wt\": dice_wt,\n",
        "                    \"volume_voxels\": volume_voxels,\n",
        "                    \"is_failure\": dice_wt < dice_threshold,\n",
        "                })\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e63841-6617-4edc-bd78-b01c2034b202",
      "metadata": {
        "id": "06e63841-6617-4edc-bd78-b01c2034b202"
      },
      "outputs": [],
      "source": [
        "def summarize_by_volume(results):\n",
        "    if len(results) == 0:\n",
        "        return {}\n",
        "\n",
        "    volumes = torch.tensor([r[\"volume_voxels\"] for r in results], dtype=torch.float32)\n",
        "    dices   = torch.tensor([r[\"dice_wt\"]        for r in results], dtype=torch.float32)\n",
        "\n",
        "\n",
        "    p33, p66 = volumes.quantile(torch.tensor([0.33, 0.66]))\n",
        "\n",
        "    def volume_group(v):\n",
        "        if v <= p33:\n",
        "            return \"Small\"\n",
        "        elif v <= p66:\n",
        "            return \"Medium\"\n",
        "        else:\n",
        "            return \"Large\"\n",
        "\n",
        "\n",
        "    for r in results:\n",
        "        r[\"volume_group\"] = volume_group(r[\"volume_voxels\"])\n",
        "\n",
        "    summary = {}\n",
        "    for group in [\"Small\", \"Medium\", \"Large\"]:\n",
        "        group_cases = [r for r in results if r[\"volume_group\"] == group]\n",
        "        if len(group_cases) == 0:\n",
        "            continue\n",
        "\n",
        "        dice_vals = torch.tensor([r[\"dice_wt\"] for r in group_cases])\n",
        "        failures  = sum(r[\"is_failure\"] for r in group_cases)\n",
        "        n_cases   = len(group_cases)\n",
        "\n",
        "        summary[group] = {\n",
        "            \"n_cases\": n_cases,\n",
        "            \"dice_mean\": dice_vals.mean().item(),\n",
        "            \"dice_std\": dice_vals.std(unbiased=False).item(),\n",
        "            \"dice_median\": dice_vals.median().item(),\n",
        "            \"failure_rate\": 100.0 * failures / n_cases\n",
        "        }\n",
        "\n",
        "    return summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32fe73b0-1b6b-49f9-9f63-14347a6e6ced",
      "metadata": {
        "id": "32fe73b0-1b6b-49f9-9f63-14347a6e6ced",
        "outputId": "f865e9e8-6b7b-46bd-83ca-86ab5a9b4101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output: torch.Size([2, 1, 512, 512])\n"
          ]
        }
      ],
      "source": [
        "%run src/ConvNext_models.ipynb\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5bfbe4-2b54-4db4-b6c7-78ecefc5033d",
      "metadata": {
        "id": "6b5bfbe4-2b54-4db4-b6c7-78ecefc5033d",
        "outputId": "6499070e-8296-44ad-cc9e-fd777b17895e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BraTS-GLI-02152-103 | Dice: 0.1824 | GT voxels: 9237 | Pred voxels: 20920 | Intersec: 2750\n",
            "BraTS-GLI-02092-102 | Dice: 0.1361 | GT voxels: 9990 | Pred voxels: 15212 | Intersec: 1715\n",
            "BraTS-GLI-02194-105 | Dice: 0.1909 | GT voxels: 14477 | Pred voxels: 17194 | Intersec: 3023\n",
            "BraTS-GLI-02105-104 | Dice: 0.1023 | GT voxels: 4560 | Pred voxels: 17436 | Intersec: 1126\n",
            "BraTS-GLI-02111-104 | Dice: 0.1190 | GT voxels: 8973 | Pred voxels: 35477 | Intersec: 2644\n",
            "BraTS-GLI-02248-101 | Dice: 0.0981 | GT voxels: 7885 | Pred voxels: 16863 | Intersec: 1214\n",
            "BraTS-GLI-02066-104 | Dice: 0.3226 | GT voxels: 24458 | Pred voxels: 24515 | Intersec: 7899\n",
            "BraTS-GLI-02063-105 | Dice: 0.2808 | GT voxels: 17722 | Pred voxels: 15898 | Intersec: 4720\n",
            "BraTS-GLI-02520-104 | Dice: 0.1509 | GT voxels: 13524 | Pred voxels: 13023 | Intersec: 2003\n",
            "BraTS-GLI-02093-102 | Dice: 0.0892 | GT voxels: 8371 | Pred voxels: 16112 | Intersec: 1092\n",
            "=== Resumen por volumen ===\n",
            "Small {'n_cases': 10, 'dice_mean': 0.12164004147052765, 'dice_std': 0.04142368212342262, 'dice_median': 0.09808380156755447, 'failure_rate': 100.0}\n",
            "Medium {'n_cases': 10, 'dice_mean': 0.12958410382270813, 'dice_std': 0.027641048654913902, 'dice_median': 0.13375408947467804, 'failure_rate': 100.0}\n",
            "Large {'n_cases': 10, 'dice_mean': 0.20714735984802246, 'dice_std': 0.06369852274656296, 'dice_median': 0.19341248273849487, 'failure_rate': 100.0}\n",
            "\n",
            "Ejemplo de primeras filas de results:\n",
            "{'case_id': 'BraTS-GLI-02152-103', 'dice_wt': 0.1823667585849762, 'volume_voxels': 9237.3525390625, 'is_failure': True, 'volume_group': 'Medium'}\n",
            "{'case_id': 'BraTS-GLI-02092-102', 'dice_wt': 0.13607732951641083, 'volume_voxels': 9990.3349609375, 'is_failure': True, 'volume_group': 'Medium'}\n",
            "{'case_id': 'BraTS-GLI-02194-105', 'dice_wt': 0.19090044498443604, 'volume_voxels': 14476.517578125, 'is_failure': True, 'volume_group': 'Large'}\n",
            "{'case_id': 'BraTS-GLI-02105-104', 'dice_wt': 0.1023479476571083, 'volume_voxels': 4560.49755859375, 'is_failure': True, 'volume_group': 'Small'}\n",
            "{'case_id': 'BraTS-GLI-02111-104', 'dice_wt': 0.11895120143890381, 'volume_voxels': 8972.5791015625, 'is_failure': True, 'volume_group': 'Medium'}\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "base_path    = \"../datasets/BRATS2024\"\n",
        "dataset = BRATSDataset_2(base_path, img_transform=transform, mask_transform = mask_transform)\n",
        "\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size   = int(0.15 * len(dataset))\n",
        "test_size  = len(dataset) - train_size - val_size\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "\n",
        "BATCH_SIZE = 6\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size   = BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset, batch_size  = BATCH_SIZE, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "num_classes = 1\n",
        "model = ConvNeXtSegmentationMF(num_classes, backbone_type='base')\n",
        "model.to(device)\n",
        "\n",
        "ckpt_path = \"pretrained_model/ConvNeXtSegmentationMF_fold1_2024.pth\"\n",
        "checkpoint = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "\n",
        "results = run_failure_analysis(model, test_loader, device, dice_threshold=0.60)\n",
        "summary = summarize_by_volume(results)\n",
        "\n",
        "print(\"=== Resumen por volumen ===\")\n",
        "for group, stats in summary.items():\n",
        "    print(group, stats)\n",
        "\n",
        "print(\"\\nEjemplo de primeras filas de results:\")\n",
        "for r in results[:5]:\n",
        "    print(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb35d212-2c42-4ea3-9cd1-34caa8e697a0",
      "metadata": {
        "id": "eb35d212-2c42-4ea3-9cd1-34caa8e697a0",
        "outputId": "4ba7370b-a35d-4c4c-c00a-0ea4600afbd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Threshold Dice = 0.2 ===\n",
            "Small {'n_cases': 10, 'dice_mean': 0.12164004147052765, 'dice_std': 0.04142368212342262, 'dice_median': 0.09808380156755447, 'failure_rate': 100.0}\n",
            "Medium {'n_cases': 10, 'dice_mean': 0.12958410382270813, 'dice_std': 0.027641048654913902, 'dice_median': 0.13375408947467804, 'failure_rate': 100.0}\n",
            "Large {'n_cases': 10, 'dice_mean': 0.20714735984802246, 'dice_std': 0.06369852274656296, 'dice_median': 0.19341248273849487, 'failure_rate': 60.0}\n",
            "\n",
            "=== Threshold Dice = 0.3 ===\n",
            "Small {'n_cases': 10, 'dice_mean': 0.12164004147052765, 'dice_std': 0.04142368212342262, 'dice_median': 0.09808380156755447, 'failure_rate': 100.0}\n",
            "Medium {'n_cases': 10, 'dice_mean': 0.12958410382270813, 'dice_std': 0.027641048654913902, 'dice_median': 0.13375408947467804, 'failure_rate': 100.0}\n",
            "Large {'n_cases': 10, 'dice_mean': 0.20714735984802246, 'dice_std': 0.06369852274656296, 'dice_median': 0.19341248273849487, 'failure_rate': 90.0}\n",
            "\n",
            "=== Threshold Dice = 0.4 ===\n",
            "Small {'n_cases': 10, 'dice_mean': 0.12164004147052765, 'dice_std': 0.04142368212342262, 'dice_median': 0.09808380156755447, 'failure_rate': 100.0}\n",
            "Medium {'n_cases': 10, 'dice_mean': 0.12958410382270813, 'dice_std': 0.027641048654913902, 'dice_median': 0.13375408947467804, 'failure_rate': 100.0}\n",
            "Large {'n_cases': 10, 'dice_mean': 0.20714735984802246, 'dice_std': 0.06369852274656296, 'dice_median': 0.19341248273849487, 'failure_rate': 100.0}\n",
            "\n",
            "=== Threshold Dice = 0.5 ===\n",
            "Small {'n_cases': 10, 'dice_mean': 0.12164004147052765, 'dice_std': 0.04142368212342262, 'dice_median': 0.09808380156755447, 'failure_rate': 100.0}\n",
            "Medium {'n_cases': 10, 'dice_mean': 0.12958410382270813, 'dice_std': 0.027641048654913902, 'dice_median': 0.13375408947467804, 'failure_rate': 100.0}\n",
            "Large {'n_cases': 10, 'dice_mean': 0.20714735984802246, 'dice_std': 0.06369852274656296, 'dice_median': 0.19341248273849487, 'failure_rate': 100.0}\n"
          ]
        }
      ],
      "source": [
        "thresholds = [0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "for thr in thresholds:\n",
        "\n",
        "    for r in results:\n",
        "        r[\"is_failure\"] = (r[\"dice_wt\"] < thr)\n",
        "\n",
        "    summary = summarize_by_volume(results)\n",
        "    print(f\"\\n=== Threshold Dice = {thr} ===\")\n",
        "    for group, stats in summary.items():\n",
        "        print(group, stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39640617-884a-49cd-a106-fef23b59ce57",
      "metadata": {
        "id": "39640617-884a-49cd-a106-fef23b59ce57"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}