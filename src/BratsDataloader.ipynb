{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdae806-d923-4a4b-9999-2dc879d31af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import nibabel as nib\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5927bfd-cffe-4b23-bed9-3c199021b9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using local\n",
      "Local\n",
      "Path BrATS2021: BrATS2021/\n",
      "Path BrATS2023: BrATS2023/\n"
     ]
    }
   ],
   "source": [
    "BrATS2021 = 0\n",
    "BrATS2023 = 0\n",
    "if os.path.isdir('/content/'):# using COLAB\n",
    "  if not os.path.isdir(\"/content/drive/MyDrive/datasets/BrATS2021/\"):\n",
    "    print(\"No se encuentra\")\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !cp kaggle.json ~/.kaggle/\n",
    "    !chmod 600 /root/.kaggle/kaggle.json\n",
    "    !kaggle datasets download -d dschettler8845/brats-2021-task1\n",
    "    !unzip  /content/brats-2021-task1.zip -d /content/BrATS\n",
    "    !mkdir -p /content/BrATS2021\n",
    "    !tar -xvf /content/BrATS/BraTS2021_Training_Data.tar -C /content/BrATS2021\n",
    "    !rm -R /content/BrATS\n",
    "    !rm /content/brats-2021-task1.zip\n",
    "    BrATS2021 =\"/content/BrATS2021\"\n",
    "  else:\n",
    "    print(\"Si se encuentra la ruta\")\n",
    "    BrATS2021 =\"/content/drive/MyDrive/datasets/BrATS2021/\"\n",
    "\n",
    "  if not os.path.isdir(\"/content/drive/MyDrive/datasets/BrATS2023/\"):\n",
    "    !kaggle datasets download -d shakilrana/brats-2023-adult-glioma -p ./BraTS2023\n",
    "#    !unzip BraTS2023/brats2023-part-1.zip -d /content/BrATS2023\n",
    "#    BrATS2023 =\"/content/BrATS2023\"\n",
    "  else:\n",
    "    BrATS2023 =\"/content/drive/MyDrive/datasets/BrATS2023/\"\n",
    "else:# using local\n",
    "    BrATS2021 = \"BrATS2021/\"\n",
    "    BrATS2023 = \"BrATS2023/\"\n",
    "print(\"Path BrATS2021:\",BrATS2021 )\n",
    "print(\"Path BrATS2023:\",BrATS2023 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229765f7-4203-41ac-a4d4-9edd5c927994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BRATSDataset_2(Dataset):\n",
    "    def __init__(self, base_path, img_transform=None, mask_transform=None, year=2023):\n",
    "        self.base_path = base_path\n",
    "        self.folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "        self.transform = img_transform\n",
    "        self.mask_transform = mask_transform  # Transformación para la máscara\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder_path = os.path.join(self.base_path, self.folders[idx])\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        t2f_file, seg_file = None, None\n",
    "\n",
    "        for nifty_file in files:\n",
    "            file_path = os.path.join(folder_path, nifty_file)\n",
    "\n",
    "            try:\n",
    "                if nifty_file.endswith('.nii') and 't2f' in nifty_file:\n",
    "                    t2f_file = nib.load(file_path).get_fdata()\n",
    "                elif nifty_file.endswith('.nii') and 'seg' in nifty_file:\n",
    "                    seg_file = nib.load(file_path).get_fdata()\n",
    "                elif nifty_file.endswith('.nii.gz') and 't2' in nifty_file:\n",
    "                    t2f_file = nib.load(file_path).get_fdata()\n",
    "                elif nifty_file.endswith('.nii.gz') and 'seg' in nifty_file:\n",
    "                    seg_file = nib.load(file_path).get_fdata()\n",
    "            except Exception as e:\n",
    "                print(f\"Error al cargar {file_path}: {e}\")\n",
    "                # Intentar con el siguiente índice si hay error\n",
    "                return self.__getitem__((idx + 1) % len(self))  \n",
    "\n",
    "        if t2f_file is None or seg_file is None:\n",
    "            print(f\"Advertencia: Archivo t2f o segmentación faltante en {folder_path}.\")\n",
    "            # Intentar con el siguiente índice si faltan archivos\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        # Encontrar el slice con mayor contenido en la máscara (más píxeles no cero)\n",
    "        max_content_slice = np.argmax(np.sum(seg_file, axis=(0,1)))\n",
    "\n",
    "        # Usar el slice con mayor contenido en la máscara\n",
    "        t2f_image = t2f_file[:, :, max_content_slice]\n",
    "        seg_image = (seg_file[:, :, max_content_slice] > 0).astype(np.uint8)  # Máscara binaria\n",
    "\n",
    "        # Convertir la imagen t2f a un tensor de PyTorch con la forma (1, H, W)\n",
    "        t2f_image = torch.tensor(t2f_image, dtype=torch.float32).unsqueeze(0)  # Añadir la dimensión de canales\n",
    "\n",
    "        # Convertir la máscara a un tensor de PyTorch con la forma (1, H, W) y tipo float\n",
    "        seg_image = torch.tensor(seg_image, dtype=torch.float32).unsqueeze(0)  # Convertir a float\n",
    "\n",
    "        # Aplicar transformaciones si están definidas\n",
    "        if self.transform:\n",
    "            t2f_image = self.transform(t2f_image)\n",
    "\n",
    "        # Aplicar la transformación de la máscara si está definida\n",
    "        if self.mask_transform:\n",
    "            seg_image = self.mask_transform(seg_image)\n",
    "\n",
    "        return t2f_image, seg_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44dfef-be78-4539-b474-75bb1071d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BRATSDataset(Dataset):\n",
    "    def __init__(self, base_path, transform=None, year=2023):\n",
    "        self.base_path = base_path\n",
    "        self.folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
    "        self.transform = transform\n",
    "        self.mask_transform = transforms.Resize((256, 256))  # Transformación para la máscara\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        folder_path = os.path.join(self.base_path, self.folders[idx])\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        # Inicializar variables para la imagen t2f y la segmentación\n",
    "        t2f_file, seg_file = None, None\n",
    "\n",
    "        for nifty_file in files:\n",
    "            file_path = os.path.join(folder_path, nifty_file)\n",
    "            if nifty_file.endswith('.nii'):  # for 2023 dataset\n",
    "                if 't2f' in nifty_file:\n",
    "                    t2f_file = nib.load(file_path).get_fdata()\n",
    "                elif 'seg' in nifty_file:\n",
    "                    seg_file = nib.load(file_path).get_fdata()\n",
    "\n",
    "            if nifty_file.endswith('.nii.gz'):  # for 2023 dataset\n",
    "                if 't2' in nifty_file:\n",
    "                    t2f_file = nib.load(file_path).get_fdata()\n",
    "                elif 'seg' in nifty_file:\n",
    "                    seg_file = nib.load(file_path).get_fdata()\n",
    "\n",
    "        if t2f_file is None or seg_file is None:\n",
    "            print(f\"Advertencia: Archivo t2f o segmentación faltante en {folder_path}.\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        # Seleccionar la imagen de la mitad del volumen\n",
    "        t2f_image = t2f_file[:, :, t2f_file.shape[2] // 2]\n",
    "        #t2f_image = torch.tensor(t2f_image, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Segmentación\n",
    "        seg_image = seg_file[:, :, seg_file.shape[2] // 2]\n",
    "        seg_image = (seg_image > 0).astype(int)  # Convierte a 1 donde la intensidad es mayor que 0\n",
    "        #seg_image = torch.tensor(seg_image, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            t2f_image = self.transform(t2f_image)\n",
    "            seg_image = self.transform(seg_image)\n",
    "        # Convertir la máscara a PIL y aplicar la transformación de redimensionado\n",
    "        seg_image = seg_image#.unsqueeze(0)  # Asegurarse de que la máscara tenga la forma correcta\n",
    "        #seg_image = self.mask_transform(seg_imag  # Transformación para cambiar el tamaño\n",
    "        #seg_image = torch.tensor(seg_image, dtype=torch.long)  # Convertir a tensor\n",
    "\n",
    "        return t2f_image, seg_image\n",
    "# Transformación opcional, si necesitas redimensionar o normalizar\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Cambia al tamaño deseado\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91711a-8dbf-4c5a-a2e7-e81ecfd3f753",
   "metadata": {},
   "source": [
    "# La siguiente está en fase de pruebas. Ejemplo de usos:\n",
    " 1️⃣  Ventana ±5 con solo T2\n",
    "ds_t2 = BRATSMultiSliceDataset(\"/datos/BRATS\", modalities=\"t2\")\n",
    "\n",
    " 2️⃣  Ventana ±3 tomando T1 contrastada y FLAIR juntos\n",
    "ds_multi = BRATSMultiSliceDataset(\"/datos/BRATS\",\n",
    "                                  modalities=[\"t1ce\", \"flair\"],\n",
    "                                  window=3)\n",
    "\n",
    " 3️⃣  Todos los slices que contengan tumor, modalidad FLAIR\n",
    "ds_flair_tumor = BRATSMultiSliceDataset(\"/datos/BRATS\",\n",
    "                                        modalities=\"flair\",\n",
    "                                        only_tumor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587476e-dd85-48f5-984d-945b3cf8537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, nibabel as nib, torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BRATSMultiSliceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset BRATS que permite:\n",
    "    • Elegir modalidades (t2, t1ce, flair…) -> 1 o N.\n",
    "    • Extraer ventana ±window alrededor del slice con +tumor, \n",
    "      o todos los slices con tumor (only_tumor=True).\n",
    "    ◇ Entrada  : tensor (C, H, W) con C = (#modalidades) * (2*window+1)\n",
    "    ◇ Etiqueta : tensor (2*window+1, H, W)  ← ahora mismo nº cortes   # ⇠ CAMBIO\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_path: str,\n",
    "        modalities=(\"t2\",),\n",
    "        window: int = 5,\n",
    "        only_tumor: bool = False,\n",
    "        img_transform=None,\n",
    "        mask_transform=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if isinstance(modalities, str):\n",
    "            modalities = (modalities,)\n",
    "        self.modalities = modalities\n",
    "        self.base_path  = base_path\n",
    "        self.window     = window\n",
    "        self.only_tumor = only_tumor\n",
    "        self.img_tf     = img_transform\n",
    "        self.mask_tf    = mask_transform\n",
    "\n",
    "        # ------- indexar (carpeta, slice_idx) --------\n",
    "        self.samples = []\n",
    "        for case in sorted(os.listdir(base_path)):\n",
    "            case_dir = os.path.join(base_path, case)\n",
    "            if not os.path.isdir(case_dir):\n",
    "                continue\n",
    "            seg_path = self._find_file(case_dir, \"seg\")\n",
    "            if seg_path is None:\n",
    "                continue\n",
    "            seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "            if self.only_tumor:\n",
    "                z_idx = np.where(seg.sum(axis=(0, 1)) > 0)[0]\n",
    "            else:\n",
    "                z_idx = [int(np.argmax(seg.sum(axis=(0, 1))))]\n",
    "\n",
    "            self.samples.extend((case_dir, z) for z in z_idx)\n",
    "\n",
    "    # ---------- utilidades ----------\n",
    "    @staticmethod\n",
    "    def _find_file(case_dir, keyword):\n",
    "        for f in os.listdir(case_dir):\n",
    "            if keyword in f and f.endswith((\".nii\", \".nii.gz\")):\n",
    "                return os.path.join(case_dir, f)\n",
    "        return None\n",
    "\n",
    "    def _load_vol(self, case_dir, keyword):\n",
    "        path = self._find_file(case_dir, keyword)\n",
    "        if path is None:\n",
    "            raise FileNotFoundError(f\"{keyword} no encontrado en {case_dir}\")\n",
    "        return nib.load(path).get_fdata()\n",
    "\n",
    "    # ---------- API ----------\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        case_dir, z = self.samples[idx]\n",
    "\n",
    "        vols = [self._load_vol(case_dir, m) for m in self.modalities]\n",
    "        seg  = self._load_vol(case_dir, \"seg\")\n",
    "\n",
    "        H, W, Z = vols[0].shape\n",
    "        w = self.window\n",
    "        z_min, z_max = max(0, z - w), min(Z, z + w + 1)\n",
    "        num_cuts = 2 * w + 1\n",
    "\n",
    "        # ---------- imágenes ----------\n",
    "        crop = np.zeros((len(vols)*num_cuts, H, W), dtype=np.float32)\n",
    "        for i, v in enumerate(vols):\n",
    "            pad = np.zeros((H, W, num_cuts), dtype=v.dtype)\n",
    "            pad[:, :, (z_min - (z - w)):(z_max - (z - w))] = v[:, :, z_min:z_max]\n",
    "            crop[i*num_cuts:(i+1)*num_cuts] = pad.transpose(2, 0, 1)\n",
    "\n",
    "        # ---------- máscaras (mismo padding) ----------\n",
    "        mask_pad = np.zeros((H, W, num_cuts), dtype=np.float32)                  # ⇠ NUEVO\n",
    "        mask_pad[:, :, (z_min - (z - w)):(z_max - (z - w))] = (seg[:, :, z_min:z_max] > 0)\n",
    "        mask_crop = mask_pad.transpose(2, 0, 1)                                  # ⇠ NUEVO\n",
    "\n",
    "        img_tensor  = torch.tensor(crop,      dtype=torch.float32)\n",
    "        mask_tensor = torch.tensor(mask_crop, dtype=torch.float32)               # ⇠ CAMBIO\n",
    "\n",
    "        if self.img_tf:\n",
    "            img_tensor = self.img_tf(img_tensor)\n",
    "        if self.mask_tf:\n",
    "            mask_tensor = self.mask_tf(mask_tensor)\n",
    "\n",
    "        return img_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688195d-60fc-43f3-859f-e00fd12c3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BratsDataLoader(nn.Module, BRATSDataset_2):\n",
    "    def __init__(self, base_path, transform=transform, batch_size=1, train_size=0.7, val_size=0.1):\n",
    "        super(BratsDataLoader, self).__init__()\n",
    "        self.base_path = base_path\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = train_size\n",
    "        self.val_size = val_size\n",
    "\n",
    "    def get_train_test(self):\n",
    "        # Crear el dataset y el DataLoader\n",
    "        dataset = BRATSDataset_2(self.base_path, self.transform)\n",
    "        \n",
    "        train_size = int(self.train_size * len(dataset))  # 70% para entrenamiento\n",
    "        val_size = int(self.val_size * len(dataset))  # 10% para validación\n",
    "        test_size = len(dataset) - train_size - val_size  # 20% para prueba\n",
    "\n",
    "        # Dividir el dataset en entrenamiento, validación y prueba\n",
    "        train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "        # Crear los DataLoaders para cada conjunto\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        print(len(train_loader))\n",
    "        print(len(test_loader))\n",
    "\n",
    "        \n",
    "        # Regresar los tres DataLoaders\n",
    "        return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49226cbd-871a-4530-bebf-6ab334085dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
