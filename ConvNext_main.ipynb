{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743497392691,
     "user": {
      "displayName": "Fernando Hernandez",
      "userId": "03780154294249447225"
     },
     "user_tz": 360
    },
    "id": "Tx0V84Ev7Myj"
   },
   "outputs": [],
   "source": [
    "#os.chdir('/content/drive/MyDrive/Escuela/Doctorado/Projects/ConvNext/ConvNext_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743497391362,
     "user": {
      "displayName": "Fernando Hernandez",
      "userId": "03780154294249447225"
     },
     "user_tz": 360
    },
    "id": "DvcraTuJ5Gcr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()  \n",
    "torch.cuda.memory_reserved()  \n",
    "import zipfile\n",
    "import os\n",
    "import nibabel as nib\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "import wandb\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "#new \n",
    "#import albumentations as A\n",
    "#from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rKxwLzT630o"
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4733,
     "status": "ok",
     "timestamp": 1743497404363,
     "user": {
      "displayName": "Fernando Hernandez",
      "userId": "03780154294249447225"
     },
     "user_tz": 360
    },
    "id": "d_cU7nu17ShJ"
   },
   "outputs": [],
   "source": [
    "%run src/ConvNext_models.ipynb\n",
    "%run src/metrics.ipynb\n",
    "%run src/hg_lossfunctions.ipynb\n",
    "%run src/trainer.ipynb\n",
    "%run src/BratsDataloader.ipynb\n",
    "%run src/Optimizer.ipynb\n",
    "%run src/UNET.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path =\"../datasets/BRATS2021/\"#\"/content/drive/MyDrive/datasets/BrATS2023/BrATS2023/\"#\"BraTS2021_Training_Data\" #\"BrATS2023\" #\"/content/drive/MyDrive/datasets/BrATS2023/BrATS2023\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)), \n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)) \n",
    "])\n",
    "\n",
    "\n",
    "# Crear el dataset y el DataLoader\n",
    "dataset = BRATSDataset_2(base_path, img_transform=transform, mask_transform = mask_transform)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))  # 70% para entrenamiento\n",
    "val_size   = int(0.15 * len(dataset))   # 15% para validación\n",
    "test_size  = len(dataset) - train_size - val_size  # 15% para prueba\n",
    "\n",
    "# Dividir el dataset en entrenamiento, validación y prueba\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Crear los DataLoaders para cada conjunto\n",
    "BATCH_SIZE = 6\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size   = BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size  = BATCH_SIZE, shuffle=False)\n",
    "print(np.shape(train_loader))\n",
    "for img, mask in train_loader:\n",
    "    print(np.shape(img))\n",
    "    print(np.shape(mask))\n",
    "    break\n",
    "# IN testing pahse\n",
    "def get_model_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    return total_params\n",
    "\n",
    "# 2. Obtener el tamaño en memoria del modelo (sin necesidad de guardarlo en archivo)\n",
    "def get_model_memory_size(model):\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "    return param_size\n",
    "def get_model_flops(model, input_size=(1, 512, 512), device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_flops = 0\n",
    "    total_params = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1743497411395,
     "user": {
      "displayName": "Fernando Hernandez",
      "userId": "03780154294249447225"
     },
     "user_tz": 360
    },
    "id": "tghYONMV7j6b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes     = 1  # Ejemplo: edema, realce, necrosis, etc.\n",
    "ConvNext_models = {  #'HyperNetSegmentation'    : HyperNetSegmentation,\n",
    "                     'ConvNeXtSegmentationMF'  : ConvNeXtSegmentationMF, # dió IoU: 0.8\n",
    "                     #'ConvNeXtUNet'            : ConvNeXtUNet,\n",
    "                     #'ConvNeXtUNet_B'          : ConvNeXtUNet_B,\n",
    "                     #ConvNext_Base'           : ConvNeXtSegmentation\n",
    "                     #'ConvNeXtSegmentationRA'  : ConvNeXtSegmentationRA #use highg resources\n",
    "}\n",
    "\n",
    "optimizers      =  { \n",
    "                     #'Adam'     : lambda model: optim.Adam(model.parameters(), lr = 0.001),\n",
    "                     'AdamW'    : lambda model: optim.AdamW(model.parameters(), lr=0.001),\n",
    "                     #'CRTAdamW' : lambda model:CRTAdamW(model.parameters(), lr = 0.001),\n",
    "                  }\n",
    "\n",
    "functions_losses = { 'BCEDiceLoss': BCEDiceLoss(),\n",
    "                     #'DSC': DiceLoss(),\n",
    "                     'BCE':nn.BCEWithLogitsLoss()\n",
    "                   }\n",
    "\n",
    "for model_name, model_class in ConvNext_models.items():      # Models \n",
    "    for optimizer_name, optimizer_class in optimizers.items(): # Optimizers\n",
    "        for losses_name, losses_class in functions_losses.items(): # Losses\n",
    "            print('------------------------ Model Name:', model_name)\n",
    "            print('------------------------ OPtimizer Name:', optimizer_name)\n",
    "            print('------------------------ Loss Name:', losses_name)\n",
    "\n",
    "            if model_name =='ConvNeXtUNet' or  model_name == 'ConvNeXtRAUNet' or model_name == 'ConvNeXtMFRAUNet':\n",
    "                model = model_class(num_classes, backbone_type='base')\n",
    "            else:\n",
    "                model       =  model_class(num_classes)   #ConvNeXtSegmentation(num_classes)\n",
    "            \n",
    "            model       = model.to(device)  # Si estás usando una GPU\n",
    "            criterion   =  losses_class #nn.BCEWithLogitsLoss()  # CrossEntropyLoss()\n",
    "            optimizer   =  optimizer_class(model)# CRTAdamW(model.parameters(), lr = 0.001)#optim.AdamW(model.parameters(), lr=0.001)# CRTAdamW\n",
    "            num_epochs  = 500\n",
    "        \n",
    "            Metrics = []\n",
    "            Conv_Next_trainer = UNetTrainer(\n",
    "                    model        = model,\n",
    "                    device       = device,\n",
    "                    optimizer    = optimizer,\n",
    "                    criterion    = criterion,\n",
    "                    train_loader = train_loader,\n",
    "                    val_loader   = val_loader,\n",
    "                    test_loader  = test_loader,\n",
    "                    epochs       = num_epochs,\n",
    "                    filename_model = model_name + '.pth'\n",
    "                )\n",
    "            total_params      = get_model_parameters(model)\n",
    "            model_memory_size = get_model_memory_size(model)/ (1024 ** 2)\n",
    "            FLOps             = get_model_flops(model)\n",
    "            print(FLOps)\n",
    "            wandb.init(project=\"ConvNext_V2_RTX4070Super_Brats2024_Round1\", config={\n",
    "                'Dataset'       : base_path, \n",
    "                'device'        : device,\n",
    "                'model name'    : model_name,\n",
    "                'epochs'        : num_epochs,\n",
    "                'batch size'    : BATCH_SIZE,\n",
    "                'loss_function' : losses_name, #criterion,\n",
    "                'optimizer'     : optimizer_name,#optimizer,\n",
    "                'total params'  :total_params,\n",
    "                'Model Size (MB)'   : model_memory_size\n",
    "            })\n",
    "            # Start training\n",
    "            Conv_Next_trainer.train()\n",
    "            # Test the model if needed\n",
    "            L_Net_images, L_Net_preds, L_Net_targets = Conv_Next_trainer.test()\n",
    "            # Visualize results\n",
    "            final_file = \"BRATS2024_\"+model_name+\"_\"+ optimizer_name+\"_\"+losses_name+'.pdf'\n",
    "            Conv_Next_trainer.visualize_results(L_Net_images, L_Net_targets, L_Net_preds, num_samples=10, save_path= final_file)\n",
    "            for th in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:\n",
    "                metrics = Conv_Next_trainer.evaluate_metrics(threshold=th)\n",
    "                Metrics.append(metrics)\n",
    "        \n",
    "            wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traiing using k-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes     = 1  # Ejemplo: edema, realce, necrosis, etc.\n",
    "ConvNext_models = {  #'UNET'    : UNet,\n",
    "                     'ConvNeXtSegmentationMF'  : ConvNeXtSegmentationMF#, # dió IoU: 0.8\n",
    "                     #'ConvNeXtUNet'            : ConvNeXtUNet,\n",
    "                     #'ConvNeXtUNet_B'          : ConvNeXtUNet_B,\n",
    "                     #'ConvNext_Base'           : ConvNeXtSegmentation\n",
    "                     #'ConvNeXtSegmentationRA'  : ConvNeXtSegmentationRA #use highg resources\n",
    "}\n",
    "\n",
    "optimizers      =  { \n",
    "                     #'Adam'     : lambda model: optim.Adam(model.parameters(), lr = 0.001),\n",
    "                     'AdamW'    : lambda model: optim.AdamW(model.parameters(), lr=0.001),\n",
    "                     #'CRTAdamW' : lambda model:CRTAdamW(model.parameters(), lr = 0.001),\n",
    "                    }\n",
    "\n",
    "functions_losses = { #'BCEDiceLoss': BCEDiceLoss(),\n",
    "                     #'DSC': DiceLoss(),\n",
    "                     'BCE':nn.BCEWithLogitsLoss()\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIolin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "def train_models_violin(\n",
    "    ConvNext_models,\n",
    "    optimizers,\n",
    "    functions_losses,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    num_classes=1,\n",
    "    device=None,\n",
    "    num_epochs=500,\n",
    "    BATCH_SIZE=6,\n",
    "    use_kfold=False,\n",
    "    k=5,\n",
    "    metrics_to_plot=None   # <- lista opcional de métricas a graficar\n",
    "):\n",
    "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dataset = train_loader.dataset\n",
    "\n",
    "    all_metrics_data = []\n",
    "\n",
    "    for model_name, model_class in ConvNext_models.items():\n",
    "        for optimizer_name, optimizer_class in optimizers.items():\n",
    "            for losses_name, losses_class in functions_losses.items():\n",
    "                \n",
    "                print('------------------------ Model:', model_name)\n",
    "                print('------------------------ Optimizer:', optimizer_name)\n",
    "                print('------------------------ Loss:', losses_name)\n",
    "\n",
    "                metrics_per_model = []\n",
    "\n",
    "                if use_kfold:\n",
    "                    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "                    fold_iter = enumerate(kf.split(dataset))\n",
    "                else:\n",
    "                    fold_iter = [(0, (range(len(dataset)), range(len(val_loader.dataset))))]\n",
    "\n",
    "                for fold, (train_idx, val_idx) in fold_iter:\n",
    "                    print(f\"===== Fold {fold+1} =====\")\n",
    "\n",
    "                    if use_kfold:\n",
    "                        train_subset = Subset(dataset, train_idx)\n",
    "                        val_subset   = Subset(dataset, val_idx)\n",
    "                        train_loader_fold = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "                        val_loader_fold   = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "                    else:\n",
    "                        train_loader_fold = train_loader\n",
    "                        val_loader_fold   = val_loader\n",
    "\n",
    "                    # Instanciar modelo\n",
    "                    if model_name in ['ConvNeXtUNet', 'ConvNeXtRAUNet', 'ConvNeXtMFRAUNet']:\n",
    "                        model = model_class(num_classes, backbone_type='base')\n",
    "                    else:\n",
    "                        model = model_class(num_classes)\n",
    "                    model = model.to(device)\n",
    "\n",
    "                    criterion = losses_class\n",
    "                    optimizer = optimizer_class(model)\n",
    "\n",
    "                    trainer = UNetTrainer(\n",
    "                        model        = model,\n",
    "                        device       = device,\n",
    "                        optimizer    = optimizer,\n",
    "                        criterion    = criterion,\n",
    "                        train_loader = train_loader_fold,\n",
    "                        val_loader   = val_loader_fold,\n",
    "                        test_loader  = test_loader,\n",
    "                        epochs       = num_epochs,\n",
    "                        filename_model = f\"{model_name}_fold{fold+1}_2021.pth\"\n",
    "                    )\n",
    "\n",
    "                    wandb.init(project=\"ConvNext_V2_Kfold_RTX4070Super_Round1\", config={\n",
    "                        'Dataset'       : 'CustomDataset', \n",
    "                        'device'        : device,\n",
    "                        'model name'    : model_name,\n",
    "                        'epochs'        : num_epochs,\n",
    "                        'batch size'    : BATCH_SIZE,\n",
    "                        'loss_function' : losses_name,\n",
    "                        'optimizer'     : optimizer_name\n",
    "                    })\n",
    "\n",
    "                    trainer.train()\n",
    "                    L_Net_images, L_Net_preds, L_Net_targets = trainer.test()\n",
    "                    # Visualize results\n",
    "                    final_file = model_name+\"_\"+ optimizer_name+\"_\"+losses_name+\"_k_\"+ str(fold)+'.pdf'\n",
    "                    trainer.visualize_results(L_Net_images, L_Net_targets, L_Net_preds, num_samples=5)\n",
    "                    metrics_fold = trainer.evaluate_metrics(threshold=0.4)\n",
    "                    print(\"Metrics Fold: \", metrics_fold )\n",
    "                    # Guardar métricas\n",
    "                    for metric_name, value in metrics_fold.items():\n",
    "                        metrics_per_model.append({\n",
    "                            \"Model\": model_name,\n",
    "                            \"Optimizer\": optimizer_name,\n",
    "                            \"Loss\": losses_name,\n",
    "                            \"Fold\": fold+1,\n",
    "                            \"Metric\": metric_name,\n",
    "                            \"Value\": value\n",
    "                        })\n",
    "                        all_metrics_data.append({\n",
    "                            \"Model\": model_name,\n",
    "                            \"Optimizer\": optimizer_name,\n",
    "                            \"Loss\": losses_name,\n",
    "                            \"Fold\": fold+1,\n",
    "                            \"Metric\": metric_name,\n",
    "                            \"Value\": value\n",
    "                        })\n",
    "\n",
    "                    wandb.finish()\n",
    "\n",
    "                # Crear DataFrame solo para este modelo y configuración\n",
    "                df_model = pd.DataFrame(metrics_per_model)\n",
    "\n",
    "                # Filtrar solo métricas deseadas si se pasa la lista\n",
    "                if metrics_to_plot is not None:\n",
    "                    df_model = df_model[df_model['Metric'].isin(metrics_to_plot)]\n",
    "\n",
    "                \n",
    "                plt.rcParams.update({\n",
    "                \"axes.titlesize\": 20,      # título\n",
    "                \"axes.labelsize\": 24,      # etiquetas de ejes\n",
    "                \"xtick.labelsize\": 21,     # ticks X\n",
    "                \"ytick.labelsize\": 21,     # ticks Y\n",
    "                \"legend.title_fontsize\": 21,\n",
    "                \"legend.fontsize\": 23\n",
    "                })\n",
    "                name_map = {\n",
    "                    \"Dice Coefficient\"     : \"DSC\",\n",
    "                    \"IoU Score\"            : \"mIoU\",\n",
    "                    \"Sensitivity (Recall)\" : \"Sensitivity\",\n",
    "                    \"Specificity\"          : \"Specificity\",\n",
    "                    \"Accuracy\"             : \"Accuracy\",\n",
    "                    \"F1-Score\"             : \"F1-score\"\n",
    "                }\n",
    "                \n",
    "                df_model[\"Metric\"] = df_model[\"Metric\"].replace(name_map)\n",
    "                \n",
    "                order = [\"DSC\", \"IoU\", \"Recall\", \"Specificity\", \"Accuracy\", \"F1\"]\n",
    "                fig, ax = plt.subplots(figsize=(10,7))#plt.figure(figsize=(24,12))\n",
    "                sns.boxplot(\n",
    "                    x=\"Metric\", y=\"Value\", hue=\"Loss\",   # opcional: hue=\"Optimizer\"\n",
    "                    data  = df_model,\n",
    "                    #notch = True # for IC 95\n",
    "                    #order=order  # <- opcional\n",
    "\n",
    "                )\n",
    "                #sns.violinplot(\n",
    "                #    x     = \"Metric\",\n",
    "                #    y     = \"Value\",\n",
    "                #    hue   = \"Loss\",   # opcional: hue=\"Optimizer\"\n",
    "                #    data  = df_model,\n",
    "                #    split = True,\n",
    "                #    inner = None, #quartile\"\n",
    "                #    bw    = 0.5,           # ajusta el ancho del KDE (kernel density)\n",
    "                #    cut   = 0\n",
    "                #)\n",
    "                ax.set_ylim(0.0, 1.0)                          # límites de 0 a 1\n",
    "                ax.set_yticks(np.arange(0.0, 1.01, 0.1))       # ticks cada 0.1\n",
    "                ax.set_title(f\"Metric distribution for {model_name} ({optimizer_name}, {losses_name})\")\n",
    "                ax.set_ylabel(\"Metric value\")\n",
    "                ax.set_xlabel(\"Metrics\")\n",
    "                ax.grid(True)\n",
    "                plt.setp(ax.get_xticklabels(), rotation=0)\n",
    "                ax.legend(title=\"Function Loss\")\n",
    "                \n",
    "                boxplot_file = f\"{model_name}_{optimizer_name}_{losses_name}.pdf\"\n",
    "                plt.savefig(boxplot_file, dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "                #ax.set_ylim(0.0, 1.0)\n",
    "                #ax.set_yticks(np.arange(0.0, 1.01, 0.1))\n",
    "                #plt.title(f\"Metric distribution for {model_name} ({optimizer_name}, {losses_name})\")\n",
    "                #plt.ylabel(\"Metric value\")\n",
    "                #plt.xlabel(\"Metrics\")\n",
    "                #plt.xticks(rotation = 0)\n",
    "                #plt.legend(title=\"Function Loss\")\n",
    "                #boxplot_file = model_name +\"_\"+ optimizer_name+\"_\"+losses_name +'.pdf'\n",
    "                #plt.savefig(boxplot_file, dpi=300, bbox_inches='tight')  # opcional: transparent=True, format=\"png\" \n",
    "                #plt.show()\n",
    "\n",
    "    return pd.DataFrame(all_metrics_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metrics = train_models_violin(\n",
    "    ConvNext_models  = ConvNext_models,\n",
    "    optimizers       = optimizers,\n",
    "    functions_losses = functions_losses,\n",
    "    train_loader     = train_loader,\n",
    "    val_loader       = val_loader,\n",
    "    test_loader      = test_loader,\n",
    "    num_classes      = 1,\n",
    "    device           = device,\n",
    "    num_epochs       = 100,\n",
    "    BATCH_SIZE       = BATCH_SIZE,\n",
    "    use_kfold        = False,\n",
    "    k                = 1,\n",
    "    metrics_to_plot  = [\"IoU Score\",\"Dice Coefficient\", \"Sensitivity (Recall)\", \"Specificity\",'Accuracy','F1-Score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_metrics.to_csv(\"ConvNeXt_all_metrics_BrATS2021_3_with_UNET_Brats2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMRLfJ7ghOc7/qQYb4g/BmD",
   "gpuType": "T4",
   "mount_file_id": "1S0uizbAOlP8EdEVIeuDO0N1Ap-co15qR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
